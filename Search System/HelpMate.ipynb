{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5e29d5-5b0b-4221-a216-8496303a70f1",
   "metadata": {},
   "source": [
    "## Build your own Project\n",
    "## Email Search AI\n",
    "\n",
    "Develop a generative search system for emails that helps organisation find and validate past decisions, stratagies, and data in a huge corpus of email threads. Here is a dataset from Kaggle that might be useful for this endeavour. A dataset from Kaggle is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49f2a1",
   "metadata": {},
   "source": [
    "## Loading datasets andimporting libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a91d4-1bac-494c-9d2b-2fb2881cf100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23056ea6-3010-40ca-9ad0-54ce95ef9361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "details = pd.read_csv('/Applications/course/Upgrad/AI&ML/gen ai/module 11-HelpmateAI/dataset_email_thread/CSV/email_thread_details.csv')\n",
    "summaries = pd.read_csv('/Applications/course/Upgrad/AI&ML/gen ai/module 11-HelpmateAI/dataset_email_thread/CSV/email_thread_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b78fc-27d6-4681-aac3-38cebc24b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a9e4c-184e-4ef4-9125-e049fded134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd08ae-1723-4dbf-9348-054bfc2b0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps and clean 'to' column\n",
    "details['timestamp'] = pd.to_datetime(details['timestamp'], errors='coerce')\n",
    "details['to'] = details['to'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29801751-b096-450f-975f-994e01091008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up email body content\n",
    "def clean_email_body(text):\n",
    "    text = re.sub(r\"(-{2,}|={2,}|Original Message|Forwarded by|From:.*\\n)\", \"\", text)\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\", text)  # Limit consecutive newlines\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)  # Remove excessive whitespace\n",
    "    return text.strip()\n",
    "\n",
    "details['cleaned_body'] = details['body'].apply(clean_email_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfff4e-cbfd-492e-82ba-c031bea1961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge summaries with email details\n",
    "merged_df = pd.merge(details, summaries, on='thread_id', how='left')\n",
    "merged_df['search_text'] = merged_df['cleaned_body'] + \" \" + merged_df['summary'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37208bad-2906-4950-99ff-aec4695cae3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8624874-f157-4966-ab6b-c37e28c1c56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display basic dataset information\n",
    "print(\"Basic Information of Email Details Dataset:\")\n",
    "print(details.info())\n",
    "print(\"\\nBasic Information of Email Summaries Dataset:\")\n",
    "print(summaries.info())\n",
    "\n",
    "# Check sample data\n",
    "print(\"\\nSample of Email Merged Data:\")\n",
    "print(merged_df[['thread_id', 'subject', 'timestamp', 'from', 'to', 'search_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37979edb-e1fa-43c2-8111-786489d5a945",
   "metadata": {},
   "source": [
    "## Embedding Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326cdf00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define paths\n",
    "CACHE_FOLDER = './model_cache'\n",
    "EMBEDDING_FILE = 'emails_with_embeddings.pkl'\n",
    "\n",
    "# Load model with persistent cache folder\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', cache_folder=CACHE_FOLDER)\n",
    "\n",
    "# Load from file if embeddings already exist\n",
    "if os.path.exists(EMBEDDING_FILE):\n",
    "    merged_df = pd.read_pickle(EMBEDDING_FILE)\n",
    "    print(\" Loaded embeddings from cache.\")\n",
    "else:\n",
    "    # Generate embeddings for each email's search text\n",
    "    merged_df['embedding'] = merged_df['search_text'].apply(lambda x: model.encode(x).tolist())\n",
    "\n",
    "    # Save the dataframe with embeddings\n",
    "    merged_df.to_pickle(EMBEDDING_FILE)\n",
    "    print(\" Embeddings computed and saved.\")\n",
    "\n",
    "# Display sample embeddings\n",
    "print(\"\\nSample Embeddings:\")\n",
    "print(merged_df[['search_text', 'embedding']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b817bf2a-da7e-42cf-b72b-b6f00feb9b8a",
   "metadata": {},
   "source": [
    "## Search Layer Sementaics search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa0619-73dd-41c6-aedc-2d7725fd8356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to perform semantic search\n",
    "def find_relevant_emails(search_query, num_results=5):\n",
    "    query_vector = model.encode(search_query)\n",
    "    similarity_scores = cosine_similarity([query_vector], merged_df['embedding'].tolist()).flatten()\n",
    "    top_matches = similarity_scores.argsort()[-num_results:][::-1]\n",
    "    return merged_df.iloc[top_matches][['thread_id', 'subject', 'timestamp', 'from', 'to', 'search_text']]\n",
    "\n",
    "# Test the semantic search function\n",
    "print(\"\\nSample Search Results:\")\n",
    "print(find_relevant_emails(\"termination meeting\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fe5379-0704-43c0-8e19-961a4f4a0b53",
   "metadata": {},
   "source": [
    "## Entity-Based Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c184eb-c538-4682-bed6-241ec97afde5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load NLP model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Entity extraction function\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "# Apply entity extraction\n",
    "merged_df['entities'] = merged_df['body'].apply(extract_entities)\n",
    "\n",
    "# Function to search by entity\n",
    "def search_by_entity(entity_name):\n",
    "    results = merged_df[merged_df['entities'].apply(lambda ents: any(entity_name in ent for ent in ents))]\n",
    "    return results[['thread_id', 'subject', 'timestamp', 'from', 'to', 'search_text']]\n",
    "\n",
    "# Test entity search function\n",
    "print(\"\\nSample Entity-Based Search Results:\")\n",
    "print(search_by_entity(\"Jeffrey\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0a767-8f45-4681-a312-571c6ba68e70",
   "metadata": {},
   "source": [
    "## Topic Based Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae330ad-0c11-4aeb-965f-9f1e6e41d765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize text data for LDA\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "doc_term_matrix = vectorizer.fit_transform(merged_df['search_text'])\n",
    "\n",
    "# Apply Latent Dirichlet Allocation for topic modeling\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(doc_term_matrix)\n",
    "\n",
    "# Assign topics to each email\n",
    "merged_df['topic'] = lda.transform(doc_term_matrix).argmax(axis=1)\n",
    "\n",
    "# Function to filter emails by topic\n",
    "def search_by_topic(topic_num):\n",
    "    return merged_df[merged_df['topic'] == topic_num][['thread_id', 'subject', 'timestamp', 'search_text']]\n",
    "\n",
    "# Test topic-based search function\n",
    "print(\"\\nSample Topic-Based Search Results:\")\n",
    "print(search_by_topic(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4411a5-2cc6-4a51-bbf8-601a76194b2b",
   "metadata": {},
   "source": [
    "## Generation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2b361-99f1-4ae9-b879-029d074ee134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Use GPU if available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Initialize summarizer with a more optimized pipeline\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"sshleifer/distilbart-cnn-12-6\",  # consider t5-small if speed is more important than quality\n",
    "    device=device\n",
    ")\n",
    "\n",
    "def batch_summarize_fast(texts, max_length=50, min_length=10, chunk_size=16):\n",
    "    \"\"\"\n",
    "    Efficient batch summarizer using Huggingface pipeline with GPU acceleration and larger input size.\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "    for i in range(0, len(texts), chunk_size):\n",
    "        batch = texts[i:i+chunk_size]\n",
    "        \n",
    "        # Truncate inputs based on token length, not character length (512 chars is too conservative)\n",
    "        batch = [text if isinstance(text, str) else \"\" for text in batch]\n",
    "\n",
    "        try:\n",
    "            result = summarizer(batch, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "            summaries.extend([res['summary_text'] for res in result])\n",
    "        except Exception as e:\n",
    "            summaries.extend([f\"Error: {str(e)}\" for _ in batch])\n",
    "\n",
    "    return summaries\n",
    "\n",
    "# Apply function directly to the DataFrame\n",
    "email_bodies = merged_df['body'].tolist()\n",
    "summaries = batch_summarize_fast(email_bodies, max_length=60, min_length=15, chunk_size=32)  # Increase batch size if GPU allows\n",
    "\n",
    "# Store results\n",
    "merged_df['generated_summary'] = summaries\n",
    "\n",
    "# Display sample summaries\n",
    "print(\"\\nGenerated Summaries:\")\n",
    "print(merged_df[['thread_id', 'subject', 'generated_summary']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "details.subject.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322708c-27ee-419b-b4be-ea9ad9db0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample queries for testing\n",
    "queries = [\n",
    "    \"New Address\",                              # Query 1\n",
    "    \"Citizens request for proposal\",            # Query 2\n",
    "    \"RE: What's Up\"                             # Query 3\n",
    "]\n",
    "\n",
    "# Function to test each query in the Search Layer and Generation Layer separately\n",
    "def test_query_for_screenshots(query, top_k=3):\n",
    "    print(f\"\\nTesting for Query: {query}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Search Layer - Retrieve top 3 results\n",
    "    print(\"\\n**Top 3 Results from Search Layer (Semantic Search):**\")\n",
    "    semantic_results = find_relevant_emails(query, top_k)\n",
    "    print(semantic_results[['thread_id', 'subject', 'timestamp', 'from', 'to', 'search_text']])\n",
    "\n",
    "    # Capture screenshot here for Search Layer\n",
    "\n",
    "    # Generation Layer - Generate a summary based on the top results\n",
    "    # Combine the top search results for summarization\n",
    "    combined_text = \" \".join(semantic_results['search_text'].tolist())\n",
    "    generated_summary = batch_summarize([combined_text])[0]\n",
    "    print(\"\\n**Final Generated Answer from Generation Layer:**\")\n",
    "    print(generated_summary)\n",
    "\n",
    "    # Capture screenshot here for Generation Layer\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run tests for each query and capture screenshots\n",
    "for query in queries:\n",
    "    test_query_for_screenshots(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf81545-bb4a-4efb-9a3d-a37f4f20fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample queries for testing\n",
    "queries = [\n",
    "    \"New Address\",                              # Query 1\n",
    "    \"Citizens request for proposal\",            # Query 2\n",
    "    \"RE: What's Up\"                             # Query 3\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d469ba",
   "metadata": {},
   "source": [
    "# Output 1 - Top 3 Results from Search Layer for Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7324cb-606c-4b15-8a36-a0920b80d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTesting for Query: {queries[0]}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Search Layer - Retrieve top 3 results for Query 1\n",
    "print(\"\\n**Top 3 Results from Search Layer (Semantic Search):**\")\n",
    "semantic_results_1 = find_relevant_emails(queries[0], num_results=3)\n",
    "print(semantic_results_1[['thread_id', 'subject', 'timestamp', 'from', 'to', 'search_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d15cd6",
   "metadata": {},
   "source": [
    "# Output 2 - Final Generated Answer from Generation Layer for Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c195d4-d7b7-45e5-9a5b-fae5bd3e3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text_1 = \" \".join(semantic_results_1['search_text'].tolist())\n",
    "generated_summary_1 = batch_summarize([combined_text_1])[0]\n",
    "print(\"\\n**Final Generated Answer from Generation Layer:**\")\n",
    "print(generated_summary_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e902ac",
   "metadata": {},
   "source": [
    "# Output 3 - Top 3 Results from Search Layer for Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e820a73-8579-44f9-a7c2-27fe752e16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTesting for Query: {queries[1]}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Search Layer - Retrieve top 3 results for Query 2\n",
    "print(\"\\n**Top 3 Results from Search Layer (Semantic Search):**\")\n",
    "semantic_results_2 = find_relevant_emails(queries[1], num_results=3)\n",
    "print(semantic_results_2[['thread_id', 'subject', 'timestamp', 'from', 'to', 'search_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8cf82",
   "metadata": {},
   "source": [
    "# Output 4 - Final Generated Answer from Generation Layer for Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b304950-0ee1-457f-9a3c-e69258f855a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text_2 = \" \".join(semantic_results_2['search_text'].tolist())\n",
    "generated_summary_2 = batch_summarize([combined_text_2])[0]\n",
    "print(\"\\n**Final Generated Answer from Generation Layer:**\")\n",
    "print(generated_summary_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47def2",
   "metadata": {},
   "source": [
    "# Output 5 - Top 3 Results from Search Layer for Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404faf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTesting for Query: {queries[2]}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Search Layer - Retrieve top 3 results for Query 3\n",
    "print(\"\\n**Top 3 Results from Search Layer (Semantic Search):**\")\n",
    "semantic_results_3 = find_relevant_emails(queries[2], num_results=3)\n",
    "print(semantic_results_3[['thread_id', 'subject', 'timestamp', 'from', 'to', 'search_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261ef9e",
   "metadata": {},
   "source": [
    "# Output 6 - Final Generated Answer from Generation Layer for Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text_3 = \" \".join(semantic_results_3['search_text'].tolist())\n",
    "generated_summary_3 = batch_summarize([combined_text_3])[0]\n",
    "print(\"\\n**Final Generated Answer from Generation Layer:**\")\n",
    "print(generated_summary_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e924441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Helpmate_AI]",
   "language": "python",
   "name": "conda-env-Helpmate_AI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
